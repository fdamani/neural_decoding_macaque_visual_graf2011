{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook \n",
    "## 1) reads and processes .mat files from Graf 2011\n",
    "## 2) computes spike counts per trial\n",
    "## 3) plots tuning curves\n",
    "## 4) builds a Poisson Independent Decoder (PID)\n",
    "## 5) builds an L1 regularized multinomial logistic regression model\n",
    "## 6) builds a Bayesian hierarchical logistic regression model (many variations) \n",
    "## 7) evaluates the three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/farhan.damani/anaconda3/lib/python3.5/site-packages/sklearn/lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "/Users/farhan.damani/anaconda3/lib/python3.5/site-packages/sklearn/qda.py:4: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import edward as ed\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import *\n",
    "from edward.models import Categorical, Empirical, Laplace,Bernoulli, Multinomial, Normal, PointMass, MultivariateNormalDiag, MultivariateNormalFullCovariance, MultivariateNormalTriL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ed.set_seed(42)\n",
    "sess = ed.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    '''Read and process mat file from Graf2011\n",
    "    \n",
    "    param array_number: {1, 2, 3, 4, 5}\n",
    "\n",
    "    return:\n",
    "        spike_times: {Nx3600} N simultaneously recorded spike trains for 3600 trials\n",
    "            (50 repeated trials of 72 direction in random order)\n",
    "        orientation_per_trial: orientation for each trial (of length 3600)\n",
    "        num_neurons: number of neurons\n",
    "        orientations: sorted set of orientations\n",
    "        num_repeats: number of repeats for each (orientation,neuron) (=50)\n",
    "        num_trials: 50 repeated trials x 72 directions\n",
    "        trial_length: length of trial (in seconds)\n",
    "    '''\n",
    "    dataStruct = scipy.io.loadmat(file_path)\n",
    "    spike_times = pd.DataFrame.from_dict(dataStruct['spk_times'])\n",
    "    orientation_per_trial = dataStruct['ori'][0]\n",
    "    num_neurons = np.shape(dataStruct['neur_param'])[0]\n",
    "    orientations = np.sort(np.unique(dataStruct['ori']))\n",
    "    trial_length = 2560e-3\n",
    "    num_repeats = 50\n",
    "    num_trials = 3600 # 50 repeated trials x 72 directions\n",
    "    num_orientations = len(orientations)\n",
    "    return spike_times, orientation_per_trial, num_neurons, orientations, trial_length, num_repeats, num_trials, num_orientations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_spike_counts(spike_times, num_neurons, num_trials):\n",
    "    '''\n",
    "        Compute spike counts for each (orientation, neuron, trial)\n",
    "        return 3D numpy array: orientation x trials x neurons\n",
    "        \n",
    "        TODO: add option to average [0 180] with responses from [180 360]\n",
    "    '''\n",
    "    spike_times_mat = spike_times.as_matrix()\n",
    "    spike_counts = np.zeros((num_orientations, num_neurons, num_repeats))\n",
    "    # for each orientation\n",
    "    for i in range(num_orientations):\n",
    "        # access indices in spike times that corresponds to ori\n",
    "        idx = np.where(orientation_per_trial == orientations[i])[0]\n",
    "        spike_times_ori = np.take(spike_times_mat, idx, axis = 1)\n",
    "        for j in range(num_neurons):\n",
    "            for k in range(num_repeats):\n",
    "                spike_counts[i, j, k] = np.count_nonzero(spike_times_ori[j][k])\n",
    "    return spike_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Filters to data\n",
    "1) spike counts observed after 1280 ms\n",
    "    - exclude\n",
    "    - use to filter neurons that do not have a significantly higher mean tc with stimulus than without\n",
    "\n",
    "2) from paper, \n",
    "To get visually driven neurons, we only accepted neurons of which the\n",
    "peak or trough of their tuning curve fell outside of the window defined\n",
    "by the mean and one s.d. of their spontaneous activity. Furthermore, we\n",
    "obtained meaningful sample of V1 neurons by only considering neurons with\n",
    "tuning curves that could be well approximated (r2   0.75) by bimodal\n",
    "circular Gaussian functions (the sum of two von Mises functions with\n",
    "different preferred orientations, amplitudes and bandwidths), allowing us\n",
    "to accommo- date for direction (mono-modal) or orientation (bi-modal)\n",
    "tuning. We obtained populations of simultaneously recorded neurons of\n",
    "sizes 40, 57, 60, 70 and 74. Each data set was obtained in a ~3-h-long\n",
    "recording session.\n",
    "\n",
    "3) average across 180 degree axis?\n",
    "\n",
    "4) if max of tc for neuron i across orientations - min of tc for neuron i across orientations is \n",
    "    not greater than 10, -> exclude neuron\n",
    "    \n",
    "5) divisive normalization\n",
    "\n",
    "'''\n",
    "\n",
    "def normalize_spike_counts(spike_counts, num_orientations, num_neurons, num_repeats):\n",
    "    '''\n",
    "        Normalize by variance of spike counts\n",
    "            for each trial\n",
    "                square spike counts across (neurons, orientations) then sum across neurons\n",
    "                divide the square of each spike count by the summed squared spike counts across neurons\n",
    "                \n",
    "        PROBLEM: mean tuning curve gives same mean for all entries\n",
    "    '''\n",
    "    spike_counts_norm = np.zeros((num_orientations, num_neurons, num_repeats))\n",
    "    for i in range(num_repeats):\n",
    "        variance_sum = np.sum(spike_counts[:, :, i]**2, axis = 1).reshape(-1,1)\n",
    "        spike_counts_norm[:, :, i] = (spike_counts[:, :, i]**2) / np.tile(variance_sum, num_neurons)\n",
    "    return spike_counts_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-a54a9182e0ea>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-a54a9182e0ea>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    best fit to the tuning curve\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "best fit to the tuning curve \n",
    "\n",
    "one von mise might get too narrow - add a constraint to keep the means separate and prevent variances from going to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Graf 2011, \"Evoked activity was estimated over the full stimulus presentation. We neglected the contamination by the blank preceding each grating because this period of the response (the first ~60 ms corresponding to typical V1 response latencies50) was of negligible duration compared with the 1,280 ms stimulus presentation time and this contamination was the same for each grating. Spontaneous activity was assessed on the last 500 ms of each blank presentation to avoid contamina- tion induced by the preceding grating. To get visually driven neurons, we only accepted neurons of which the peak or trough of their tuning curve fell outside of the window defined by the mean and one s.d. of their spontaneous activity. Furthermore, we obtained meaningful sample of V1 neurons by only considering neurons with tuning curves that could be well approximated (r2   0.75) by bimodal circular Gaussian functions (the sum of two von Mises functions with different preferred orientations, amplitudes and bandwidths), allowing us to accommo- date for direction (mono-modal) or orientation (bi-modal) tuning.\"\n",
    "\n",
    "\n",
    "\n",
    "From Montijn 2014, \"To further parameterize neuronal orientation tuning, we also calculated each neuron's preferred direction by fitting a double von Mises distribution to the neuron's responses, where the peaks of both von Mises functions are opposite to each other (separated by 180°):\n",
    "\n",
    "$$f(x∣∣θ,κ1,κ2,μ0)= \\frac{e^{κ_1cos(x−θ)}}{2πI_0(κ_1)} + \\frac{e^{κ_2cos(x+π−θ)}}{2πI_0(κ_2)}+μ_0$$\n",
    "(1)\n",
    "Here, I0(κ) is the modified Bessel function of order 0 and x represents the stimulus angle. As can be seen in the equation, we defined the free parameters as θ (preferred direction), κ1 (concentration parameter at θ), κ2 (concentration parameter at θ +π) and μ0 (baseline response). A neuron's preferred direction was defined as the angle with the highest concentration parameter (which could be either κ1 or κ2).\"\n",
    "\n",
    "## is this based on training data or all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_mean_tc(spike_counts):\n",
    "    return np.mean(spike_counts, axis=2)\n",
    "\n",
    "def compute_var_tc(spike_counts):\n",
    "    return np.var(spike_counts, axis=2)\n",
    "\n",
    "def compute_cov_tc(spike_counts):\n",
    "    tc_cov = np.zeros((num_neurons, num_neurons, num_orientations))\n",
    "    for i in range(num_orientations):\n",
    "        tc_cov[:, :, i] = np.cov(spike_counts[i])\n",
    "    return tc_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_preferred_orientation(mean_tc, num_neurons):\n",
    "    '''max of tuning curve across orientations'''\n",
    "    pref_ori = np.zeros(147)\n",
    "    for i in range(num_neurons):\n",
    "        pref_ori[i] = np.argmax(mean_tc[:,i])\n",
    "    return pref_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pref_ori' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-635085cd56b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpref_ori\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pref_ori' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(pref_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_to_well_tuned_neurons(mean_tc, thresh):\n",
    "    '''Filter to well tuned neurons, example thresh = 10'''\n",
    "    maxdiff = np.max(mean_tc, axis=0) - np.min(mean_tc, axis=0)\n",
    "    ind_tuned = np.where(maxdiff > thresh)[0]\n",
    "    return ind_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# path to mat file from Graf 2011\n",
    "file_path = '../../data/graf_V1data/array_3.mat'\n",
    "\n",
    "# read and process data\n",
    "spike_times, orientation_per_trial, num_neurons, orientations, trial_length,\\\n",
    "    num_repeats, num_trials, num_orientations = read_data(file_path)\n",
    "\n",
    "# compute spike counts\n",
    "spike_counts = compute_spike_counts(spike_times, num_neurons, num_trials)\n",
    "\n",
    "# compute tuning curves\n",
    "mean_tc = compute_mean_tc(spike_counts)\n",
    "var_tc = compute_var_tc(spike_counts)\n",
    "cov_tc = compute_cov_tc(spike_counts)\n",
    "\n",
    "# identify indices for well-tuned neurons\n",
    "ind_well_tuned = filter_to_well_tuned_neurons(mean_tc, 10)\n",
    "\n",
    "# normalize spike counts\n",
    "spike_counts_norm = normalize_spike_counts(spike_counts, num_orientations, num_neurons, num_repeats)\n",
    "\n",
    "# compute normalized tuning curves\n",
    "mean_tc_norm = compute_mean_tc(spike_counts_norm)\n",
    "var_tc_norm = compute_var_tc(spike_counts_norm)\n",
    "cov_tc_norm = compute_cov_tc(spike_counts_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spike_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_tc[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import vonmises\n",
    "kappa = 3.99\n",
    "x = np.linspace(vonmises.ppf(0.01, kappa), vonmises.ppf(0.99, kappa), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.special import j0\n",
    "# besel function of the 0th order\n",
    "j0(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def von_mises(k1, k2, mu1, mu2, x):\n",
    "    first_term = np.exp(k1 * np.cos(x-mu1)) / (2 * np.pi * j0(k1))\n",
    "    second_term = np.exp(k2 * np.cos(x-mu2)) / (2 * np.pi * j0(k2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mean_tc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mean_tc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot mean tuning curve for 10 well tuned neurons\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(orientations, mean_tc[:, ind_well_tuned[0:10]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot variance tuning curve for 10 well tuned neurons\n",
    "plt.plot(orientations, var_tc[:, ind_well_tuned[0:10]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION METRICS\n",
    "1) Figure 4 from Graf '11 measuring orientation discrimination accuracy.\n",
    "Compute likelihood ratio tests between $\\theta$ and $\\theta + \\delta \\theta$ where $\\delta = \\in \\{5, 10, 15, 20, 25, 30\\}$ across all 72 values of $\\theta$. So train each model on 35 samples and test on 15 for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def likelihood_ratio_test(likelihood_one, likelihood_two):\n",
    "    diff = likelihood_one - likelihood_two\n",
    "    diff[diff > 0] = 1\n",
    "    diff[diff < 0] = 2\n",
    "    return diff\n",
    "\n",
    "def likelihood(w_i, r_i, b_i):\n",
    "    '''Compute data likelihood given w, r, b for stimulus i'''\n",
    "    #return np.log(np.sum(np.dot(w_i, r_i.T)) + b_i)\n",
    "    return np.log(np.dot(w_i, r_i.T) + b_i)\n",
    "    \n",
    "\n",
    "def evaluate_model(x_test, w, b):    \n",
    "    probabilities = np.zeros((72, 6)) # orientations x deltas\n",
    "    deltas = [1, 2, 3, 4, 5, 6]\n",
    "    # for each ori\n",
    "    for i in range(72):\n",
    "        # for each delta\n",
    "        for delta in deltas:\n",
    "            test_data = (np.concatenate((x_test[i], x_test[(i+delta) % 72])))\n",
    "            test_labels = np.repeat(np.arange(1,3), 15)\n",
    "            likelihoods_one = likelihood(w[i], test_data, b[i])\n",
    "            likelihoods_two = likelihood(w[(i+delta) % 72], test_data, b[(i+delta) % 72])\n",
    "            pred_labels = likelihood_ratio_test(likelihoods_one, likelihoods_two)\n",
    "            probabilities[i][delta-1] = sklearn.metrics.accuracy_score(pred_labels, test_labels)\n",
    "    return np.mean(probabilities, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multiclass_log_likelihood(c, w, x, b):\n",
    "    logit = np.dot(w[c], x.T) + b[c]\n",
    "    numerator = np.exp(logit)\n",
    "    denominator = 0\n",
    "    C = 36\n",
    "    for i in range(C):\n",
    "        denominator = denominator + np.exp(np.dot(w[i], x.T) + b[i])\n",
    "    return np.log(numerator / denominator)\n",
    "\n",
    "def evaluate_multiclass_model(x, w, b):    \n",
    "    deltas = [1, 2, 3, 4, 5, 6]\n",
    "    C = 36\n",
    "    probabilities = np.zeros((C, len(deltas))) # orientations x deltas\n",
    "\n",
    "    # for each ori\n",
    "    for i in range(C):\n",
    "        # for each delta\n",
    "        for delta in deltas:\n",
    "            test_data = (np.concatenate((x[i], x[(i+delta) % C])))\n",
    "            test_labels = np.repeat(np.arange(1,3), 15)\n",
    "            likelihoods_one = multiclass_log_likelihood(i, w, test_data, b)\n",
    "            likelihoods_two = multiclass_log_likelihood((i+delta)%C, w, test_data, b)\n",
    "            pred_labels = likelihood_ratio_test(likelihoods_one, likelihoods_two)\n",
    "            \n",
    "            probabilities[i][delta-1] = sklearn.metrics.accuracy_score(pred_labels.astype(int), test_labels)\n",
    "    return np.mean(probabilities, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_model(x_test, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-892425177698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#plt.plevaluate_multiclass_model(x_test_scaled, qw_mod.eval().T, qb_mod.eval())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#plt.plot(xticks, evaluate_multiclass_model(x_test_scaled, w_vi.T, b_vi))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "# green is sklearn l1\n",
    "# blue is with Stan normal(0,1) prior\n",
    "# yellow is VI with sample covariance prior\n",
    "# brown is edward normal(0, .1) prior\n",
    "# red is PID\n",
    "\n",
    "xticks = [5, 10, 15, 20, 25, 30]\n",
    "#plt.plot(xticks, evaluate_multiclass_model(x_test_scaled, w_model.T, b_model))\n",
    "#plt.plot(xticks, evaluate_multiclass_model(x_test_scaled, beta, intercept))\n",
    "#plt.plot(xticks,evaluate_multiclass_model(x_test_scaled, lr.coef_, lr.intercept_))\n",
    "#plt.plot(xticks, evaluate_multiclass_model(x_test_scaled, beta_ori, intercept_ori))\n",
    "#plt.plevaluate_multiclass_model(x_test_scaled, qw_mod.eval().T, qb_mod.eval())\n",
    "\n",
    "plt.plot(xticks, evaluate_model(x_test_scaled, w, b))\n",
    "#plt.plot(xticks, evaluate_multiclass_model(x_test_scaled, w_vi.T, b_vi))\n",
    "\n",
    "#plt.plot(xticks,evaluate_multiclass_model(x_test_scaled, qw_mod.eval().T, qb_mod.eval()))\n",
    "plt.plot(xticks,([ 0.91157407,  0.94722222,  0.97685185,  0.98842593,  0.99583333,\n",
    "        0.99768519]))\n",
    "plt.plot(xticks,([ 0.92037037,  0.96435185,  0.98148148,  0.9912037 ,  0.99768519,\n",
    "        0.99722222]))\n",
    "\n",
    "#plt.plot(xticks, evaluate_multiclass_model(x_test_scaled, qw_mod.eval().T, qb_mod.eval()))\n",
    "\n",
    "plt.ylabel(\"probability correct\")\n",
    "plt.xlabel(\"orientation difference (degrees)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets build a Poisson Independent Decoder (PID). We assume each neuron's stimulus-specific spike counts is Poisson distributed and statistically independent across neurons. The rate parameter $w_i(\\theta)$ is the logarithm of the mean neuronal tuning function for neuron i across trials for stimulus $\\theta$.\n",
    "\n",
    "### The likelihood function is $\\log L(\\theta) = \\sum_{i=1}^N w_i(\\theta)r_i + b(\\theta)$. The offset b incorporates overall bias in coverage of orientations and is the sum of the mean tuning curve across neurons for stimulus $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_mean_tc_training(x):\n",
    "    '''compute mean tuning curve (mean of samples for a given orientation,neuron) given training data (orientation,samples) x neurons'''\n",
    "    mean_tc = np.zeros((x.shape[0], x.shape[2]))\n",
    "    for i in range(72):\n",
    "        mean_tc[i] = np.mean(x[i], axis = 0)\n",
    "    return mean_tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter to well-tuned neurons then rotate axes so we have ori x samples x neurons\n",
    "spike_counts_filt = np.rollaxis(np.rollaxis(spike_counts[:, ind_well_tuned, :], 2), 1)\n",
    "#spike_counts_filt = np.rollaxis(np.rollaxis(spike_counts, 2), 1)\n",
    "# train/test split\n",
    "inds = np.arange(50)\n",
    "train_ind = np.random.choice(inds, size = 35, replace = False)\n",
    "test_ind =  np.array([x for x in inds if x not in train_ind])\n",
    "x_train, x_test = spike_counts_filt[:, train_ind, :], spike_counts_filt[:, test_ind, :]\n",
    "# compute mean training curve on training data\n",
    "mean_tc_train = compute_mean_tc_training(x_train)\n",
    "# weights are log of mean tuning curve\n",
    "w = np.log(mean_tc_train)\n",
    "b = np.sum(w, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((72, 35, 66), (72, 15, 66))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### 0-180 degrees only\n",
    "x_train_half = x_train[0:36]\n",
    "x_test_half = x_test[0:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 35, 66)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_half.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def likelihood_(w_i, r_i, b_i):\n",
    "    '''Compute data likelihood given w, r, b for stimulus i'''\n",
    "    return np.log(np.sum(np.dot(w_i, r_i.T)) + b_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_likelihood(w, x_train, b, stimulus_choice):\n",
    "    '''plot likelihood of stimulus-specific spike train as a function of model choice'''\n",
    "    sx = []\n",
    "    for i in range(72):\n",
    "        sx.append(likelihood(w[i], x_train[stimulus_choice], b[i]))\n",
    "    fig = plt.plot(sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def likelihood_ratio_test_(w, x_train, b, ori1, ori2):\n",
    "    '''given a population response, compute likelihood ratio test comparing two orientation models'''\n",
    "    val = likelihood(w[ori1], x_train, b[ori1]) - likelihood(w[ori2], x_train, b[ori2])\n",
    "    if val > 0:\n",
    "        return ori1\n",
    "    else:\n",
    "        return ori2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# likelihood comparison -- which model provides best explanation of the data?,\n",
    "plot_likelihood(w, x_train, b, 1) # for example, we fit spike trains from ori 1 against all possible models\n",
    "plot_likelihood(w, x_test, b, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1260, 66)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### DATA PROCESSING\n",
    "\n",
    "num_classes = 72\n",
    "C = 72\n",
    "\n",
    "\n",
    "Xtrain = x_train.reshape(x_train.shape[0] * x_train.shape[1], x_train.shape[2])\n",
    "Xtest = x_test.reshape(x_test.shape[0] * x_test.shape[1], x_test.shape[2])\n",
    "Ytrain = np.repeat(np.arange(C), x_train.shape[1])\n",
    "Ytest = np.repeat(np.arange(C), x_test.shape[1])\n",
    "\n",
    "\n",
    "#Xtrain = x_train.reshape(x_train.shape[0] * x_train.shape[1], x_train.shape[2])\n",
    "#Xtest = x_test.reshape(x_test.shape[0] * x_test.shape[1], x_test.shape[2])\n",
    "\n",
    "#Ytrain = np.repeat(np.arange(72), x_train.shape[1])\n",
    "#Ytest = np.repeat(np.arange(72), x_test.shape[1])\n",
    "\n",
    "N,D = Xtrain.shape[0], Xtrain.shape[1]\n",
    "\n",
    "Xtrain_scaled = sklearn.preprocessing.scale(Xtrain)\n",
    "Xtest_scaled = sklearn.preprocessing.scale(Xtest)\n",
    "Ytrain_hot = tf.one_hot(Ytrain, depth=C).eval()\n",
    "Ytest_hot = tf.one_hot(Ytest, depth=C).eval()\n",
    "\n",
    "x_train_scaled_3d = np.zeros((num_classes,35,D))\n",
    "x_test_scaled_3d = np.zeros((num_classes,15,D))\n",
    "for i in range(num_classes):\n",
    "    x_test_scaled_3d[i] = Xtest_scaled[i*15:i*15+15]\n",
    "    x_train_scaled_3d[i] = Xtrain_scaled[i*35:i*35+35]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets build a L1 regularized multinomial multi-class logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify model\n",
    "lr = sklearn.linear_model.LogisticRegression(penalty='l1', fit_intercept=True)\n",
    "\n",
    "# fit the model\n",
    "lr.fit(Xtrain_scaled, np.repeat(np.arange(C),35))\n",
    "\n",
    "## predict labels and probability distributions on test data\n",
    "#labels_test = lr.predict(sklearn.preprocessing.scale(Xtest_scaled))\n",
    "#scores_test = lr.predict_proba(sklearn.preprocessing.scale(Xtest_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 15, 66)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_scaled_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.81944444,  0.95648148,  0.98611111,  0.99351852,  0.99722222,\n",
       "        0.99722222])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_multiclass_model(x_test_scaled_3d, lr.coef_, lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_one_versus_all(y_test, scores):\n",
    "    '''AUC scores for one versus all classification on test data across all classes'''\n",
    "    aucs = []\n",
    "    for j in range(72):\n",
    "        sx = []\n",
    "        for i in range(len(y_test)):\n",
    "            if y_test[i] == (j+1):\n",
    "                sx.append(int(1))\n",
    "            else:\n",
    "                sx.append(int(0))\n",
    "        aucs.append(sklearn.metrics.roc_auc_score(np.array(sx),scores[:,j]))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.scatter(np.arange(72),aucs)\n",
    "    plt.xlabel('class')\n",
    "    plt.ylabel('auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_one_versus_one(y_test, scores, delta):\n",
    "    '''AUC scores for one class versus one class on test data across all classes\n",
    "        delta, int : discriminate between class and class + delta    \n",
    "    '''\n",
    "    aucs = []\n",
    "    for j in range(1,73):\n",
    "        inds = np.concatenate((np.where(y_test == (j))[0], np.where(y_test == (((j-1)+delta) % 72) + 1)[0]))\n",
    "        #print(y_test[inds])\n",
    "        #print(scores[inds,j-1])\n",
    "        y = (y_test[inds] == j).astype(int)\n",
    "        aucs.append((sklearn.metrics.roc_auc_score(y, scores[inds,j-1])))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.scatter(np.arange(72),aucs)\n",
    "    plt.xlabel('class')\n",
    "    plt.ylabel('auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_one_versus_one(y_test, scores_test, 1)\n",
    "evaluate_one_versus_one(y_test, scores_test, 2)\n",
    "evaluate_one_versus_one(y_test, scores_test, 5)\n",
    "evaluate_one_versus_one(y_test, scores_test, 10)\n",
    "evaluate_one_versus_one(y_test, scores_test, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM model from Graf 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aucs_svm = []\n",
    "w_svm = []\n",
    "b_svm = []\n",
    "C = 72\n",
    "\n",
    "aucs_svm_local = []\n",
    "for i in range(0,C):\n",
    "    clf = svm.SVC(kernel='linear')\n",
    "    #train_data = np.concatenate([x_train[(i+d)%72], x_train[i]])\n",
    "    #test_data = np.concatenate([x_test[(i+d)%72], x_test[i]])\n",
    "\n",
    "    train_data = np.concatenate([x_train[(i+1)%C], x_train[i]])\n",
    "    test_data = np.concatenate([x_test[(i+1)%C], x_test[i]])\n",
    "    clf.fit(train_data, np.repeat(np.arange(-1,2, step=2), 35))\n",
    "    w_svm.append(clf.coef_[0])\n",
    "    b_svm.append(clf.intercept_[0])\n",
    "\n",
    "    aucs_svm_local.append(sklearn.metrics.accuracy_score(clf.predict(test_data), np.repeat([-1,1],15)))\n",
    "    aucs_svm.append(np.mean(aucs_svm_local))\n",
    "w_svm = np.array(w_svm)\n",
    "b_svm = np.array(b_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_ll(stimulus, weights, intercepts, data):\n",
    "    '''\n",
    "    log L(\\theta_i) = \\sum_{k=2}^i log LR(\\theta_k, \\theta_{k-1})\n",
    "    \n",
    "    '''\n",
    "    log_likelihood = 0\n",
    "    for i in range(2, stimulus+1):\n",
    "        log_likelihood = log_likelihood + compute_log_lr(i, weights, intercepts, data)\n",
    "    return log_likelihood / np.sum(log_likelihood)\n",
    "def compute_log_lr(stimulus, weights, intercepts, data):\n",
    "    ll = np.sum(weights[stimulus-1]*data,axis=1) + intercepts[stimulus-1]\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.concatenate([x_test[(1)%C], x_test[2]])\n",
    "x = compute_ll(2, w_svm, b_svm, data) - compute_ll(3, w_svm, b_svm, data)\n",
    "sklearn.metrics.accuracy_score(np.repeat(np.arange(0,2), 15), x > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60,)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(np.arange(0,2), 30).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(np.repeat(np.arange(0,2), 15), x > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(2, C+1):\n",
    "    data = np.concatenate([x_test[(i-1)%C], x_test[(i%C)]])\n",
    "    x = compute_ll(i, w_svm, b_svm, data) - compute_ll((i+1)%C, w_svm, b_svm, data)\n",
    "    acc.append(sklearn.metrics.accuracy_score(np.repeat(np.arange(0,2), 15), x < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61267605633802802"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write a function that computes log L(data; stimulus) -> so we specify the data and what stimulus we want and then we get log likelihood values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 66)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_svm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((w_svm[0]*x_test[1]),axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(-1,2, step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99985421,  1.00000913,  1.00000869,  1.5280152 ,  1.64711368,\n",
       "        0.99991817,  1.00002585,  2.05081325,  1.27248537,  1.11339972,\n",
       "        1.25520706,  1.43436115,  1.02412011,  1.00039105,  1.23687387,\n",
       "        1.55026493,  1.00011338,  1.1338002 ,  1.44887515,  1.35048896,\n",
       "        1.21286996,  1.00040947,  1.53340711,  1.29605826,  1.56474806,\n",
       "        1.59758385,  1.19058291,  0.99985272,  1.30316249,  1.00017426,\n",
       "        1.08326209,  1.78100884,  0.99959018,  0.99952498,  1.14417239,\n",
       "       -1.62186017, -3.56552217, -1.11627546, -2.03894788, -2.35280472,\n",
       "       -1.76635965, -1.00044517, -1.0000293 , -1.28418647, -1.81993908,\n",
       "       -1.09839415, -0.99992851, -1.24180625, -0.99971048, -0.99992876,\n",
       "       -1.98063477, -1.02806002, -2.27813527, -1.00021073, -0.99999638,\n",
       "       -0.99988914, -1.80582531, -0.99992851, -0.99966875, -1.63221942,\n",
       "       -1.28316921, -1.00046254, -2.31339842, -0.99967384, -1.3534269 ,\n",
       "       -1.30343685, -1.48464686, -1.22753246, -1.32216052, -2.08526603])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(w_svm[0]*r, axis=1) + b_svm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((66,), (66,), (70, 66))"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(w_svm[0]*r, axis=0).shape, w_svm[0].shape, r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_ll_svm = np.zeros((72,70))\n",
    "for i in range(C):\n",
    "    if i == 0:\n",
    "        log_ll_svm[i] = 0\n",
    "        continue\n",
    "    r = np.concatenate([x_train[(i-1)%C], x_train[i]])\n",
    "    llr = np.sum(w_svm[i]*r, axis=1) + b_svm[i]\n",
    "    llr = llr / np.sum(llr) # scale llrs\n",
    "    log_ll_svm[i] = log_ll_svm[i-1] + llr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_ll_svm = np.zeros((72,70))\n",
    "w_d = np.zeros((72,66))\n",
    "w_svm[0] = 0\n",
    "for i in range(C):\n",
    "    w_d[i] = w_svm[(i+1)%C] - w_svm[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00780162, -0.02538135, -0.01285947, ...,  0.01064625,\n",
       "         0.00416119, -0.00745489],\n",
       "       [ 0.01016356,  0.02862334,  0.0015774 , ..., -0.00854087,\n",
       "         0.01254639,  0.00528252],\n",
       "       [ 0.01562254,  0.04733449, -0.02445935, ...,  0.00323274,\n",
       "         0.0027448 , -0.00191086],\n",
       "       ..., \n",
       "       [ 0.05488365,  0.01229697,  0.00454152, ..., -0.0244175 ,\n",
       "        -0.00343365,  0.02993379],\n",
       "       [-0.00735064, -0.00951106, -0.00539935, ..., -0.01061533,\n",
       "         0.01910915, -0.01344544],\n",
       "       [-0.00025439,  0.00695712, -0.00223221, ...,  0.02283983,\n",
       "        -0.00261978, -0.01291241]])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.61330046,  2.56464045,  2.03756082,  2.44418738,  2.74065742,\n",
       "        1.85330084,  3.81862399,  2.52582376,  3.85899648,  2.65572377,\n",
       "        2.94858623,  3.98599346,  3.45944799,  2.94943077,  2.61505058,\n",
       "        2.94798479,  2.08504589,  3.08739288,  2.92888464,  2.30167625,\n",
       "        2.80233979,  2.21478283,  3.25631735,  3.13889484,  2.68246207,\n",
       "        2.55969725,  2.30358881,  2.90440798,  2.71754126,  1.80195695,\n",
       "        1.32249996,  3.15898258,  2.38556443,  1.81585779,  3.07148664,\n",
       "        2.88500923,  2.22155426,  2.01579145,  3.76670941,  1.79281343,\n",
       "        1.68520942,  3.50151403,  2.84818844,  2.24310858,  2.7596632 ,\n",
       "        2.35713918,  2.89026073,  2.87976437,  2.49630308,  2.82758617,\n",
       "        2.17053346,  2.34667721,  1.82665937,  1.59155578,  1.72729581,\n",
       "        2.09053037,  2.34920065,  3.07437143,  2.87205435,  2.82992113,\n",
       "        1.78188986,  3.14084388,  2.38658102,  2.6524941 ,  2.29643785,\n",
       "        1.48922007,  3.38214053,  2.80219672,  2.19008901,  2.84969461])"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(w_svm[0]*r, axis=1) + b_svm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.        ,    0.        ,    0.        , ...,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [   3.10986624,    2.57714643,    3.13005735, ...,    0.99958555,\n",
       "           0.99966977,    1.31169172],\n",
       "       [   5.59068993,    5.43461025,    6.5607529 , ...,    2.24206468,\n",
       "           2.58269256,    3.89885701],\n",
       "       ..., \n",
       "       [ 196.34640817,  222.99713332,  223.61414606, ...,  117.70292896,\n",
       "          95.4575153 ,  108.18123393],\n",
       "       [ 198.28610113,  227.3345811 ,  227.52521459, ...,  118.70339009,\n",
       "          96.45723921,  109.18130487],\n",
       "       [ 200.62194598,  229.76633405,  229.83500172, ...,  119.70326342,\n",
       "          97.4567742 ,  110.49577146]])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_ll_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# subset of tuned neurons, with single tau\n",
    "plt.plot([1,2,3,4,5,6], aucs_svm)\n",
    "plt.plot([1,2,3,4,5,6], evaluate_multiclass_model(x_test_scaled_3d, qw_mod.eval().T, qb_mod.eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot([1,2,3,4,5,6], aucs_svm)\n",
    "plt.plot([1,2,3,4,5,6], evaluate_multiclass_model(x_test_scaled_3d, qw_mod.eval().T, qb_mod.eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all neurons, sparsity param for each class \n",
    "\n",
    "plt.plot([1,2,3,4,5,6], aucs_svm)\n",
    "plt.plot([1,2,3,4,5,6], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tau.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qw_mod = tf.concat([qw.mean(), np.zeros((D,1))], axis=1)\n",
    "qb_mod = tf.concat([qb.mean(), np.zeros((1))], axis=0)\n",
    "logits = tf.matmul(tf.cast(Xtest_scaled, tf.float32), qw_mod) + qb_mod\n",
    "print(compute_average_auc(tf.nn.softmax(logits).eval(), Ytest_hot))\n",
    "print(evaluate_multiclass_model(x_test_scaled_3d, qw_mod.eval().T, qb_mod.eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qw_mod = tf.concat([qw.mean(), np.zeros((D,1))], axis=1)\n",
    "qb_mod = tf.concat([qb.mean(), np.zeros((1))], axis=0)\n",
    "logits = tf.matmul(tf.cast(Xtest_scaled, tf.float32), qw_mod) + qb_mod\n",
    "print(compute_average_auc(tf.nn.softmax(logits).eval(), Ytest_hot))\n",
    "print(evaluate_multiclass_model(x_test_scaled_3d, qw_mod.eval().T, qb_mod.eval()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets build a Bayesian multinomial multi-class logistic regression model\n",
    "$$p(\\theta^{(i)} = c | r^{(i)}, w^{(c)}) = \\frac{\\exp{(w^{(c)T}r^{(i)})}}{\\sum_{j=1}^C(w^{(j)T}r^{(i)})}$$\n",
    "$$p(w^{(c)}|\\Lambda^{(c)}) = \\mathcal{N}(0, \\Lambda^{(c)}), \\Lambda^{(c)} \\in \\mathcal{R^{\\text{NxN}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_average_auc(predictions, labels):\n",
    "    classes = labels.shape[1]\n",
    "    aucs = np.zeros((classes))\n",
    "    for i in range(classes):\n",
    "        aucs[i] = sklearn.metrics.roc_auc_score(labels[:,i], predictions[:,i])\n",
    "    return np.mean(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tridiagonal prior -> variational EM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def design_precision_matrix():\n",
    "    w_covs = []\n",
    "    tau = tf.nn.softplus(tf.Variable(tf.random_normal([D])))\n",
    "    sparsity = tf.nn.softplus(tf.Variable(tf.random_normal([D])))\n",
    "    # for each neuron\n",
    "    for d in range(D):\n",
    "        # Design precision matrix\n",
    "        A = np.zeros((C-1,C))\n",
    "        for i in range(C-1):\n",
    "            A[i,i] = -1\n",
    "            A[i,i+1] = 1\n",
    "        precision = A.T.dot(A) #+ .1 * np.identity(C) # precision = A^T.dot(A)\n",
    "        precision = tau[d] * precision + sparsity[d] * np.identity(C)\n",
    "        precision = precision + .1 * np.identity(C) # guarantees full rank\n",
    "\n",
    "        cov = tf.matrix_inverse(precision)[:-1,:-1]\n",
    "        w_covs.append(cov)\n",
    "    \n",
    "    w_cov = tf.stack(w_covs)\n",
    "\n",
    "        #w_cov = tf.tile(tf.expand_dims(cov, 0), [D, 1, 1])\n",
    "    return w_cov\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1260, 66), (2520,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_scaled.shape, Ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for each neuron\n",
    "for d in range(D):\n",
    "    # Design precision matrix\n",
    "    A = np.zeros((C-1,C))\n",
    "    # for each orientation\n",
    "    for i in range(C-1):\n",
    "        A[i,i] = -1\n",
    "        A[i,i+1] = 1\n",
    "    precision = A.T.dot(A) #+ .1 * np.identity(C) # precision = A^T.dot(A)\n",
    "    precision[0,0] = 2.0\n",
    "    precision[C-1, C-1] = 2.0\n",
    "    precision[0, C-1] = -1.0\n",
    "    precision[C-1, 0] = -1.0\n",
    "    \n",
    "    precision = precision + sparsity * np.identity(C)\n",
    "    precision = precision + .1 * np.identity(C) # guarantees full rank\n",
    "\n",
    "    cov = tf.matrix_inverse(precision)[:-1,:-1]\n",
    "    w_covs.append(tf.cast(cov, tf.float64))\n",
    "w_cov = tf.stack(w_covs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Design precision matrix\n",
    "A = np.zeros((C-1,C))\n",
    "# for each orientation\n",
    "for i in range(C-1):\n",
    "    A[i,i] = -1\n",
    "    A[i,i+1] = 1\n",
    "precision = A.T.dot(A) #+ .1 * np.identity(C) # precision = A^T.dot(A)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -1.,  0., ...,  0.,  0.,  0.],\n",
       "       [-1.,  2., -1., ...,  0.,  0.,  0.],\n",
       "       [ 0., -1.,  2., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  2., -1.,  0.],\n",
       "       [ 0.,  0.,  0., ..., -1.,  2., -1.],\n",
       "       [ 0.,  0.,  0., ...,  0., -1.,  1.]])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0., -1.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0., -1., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., -1.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0., -1.,  1.]])"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision[0,0] = 2\n",
    "precision[C-1, C-1] = 2\n",
    "precision[0, C-1] = -1\n",
    "precision[C-1, 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t': 1, 'loss': 76521.016}\n",
      "{'t': 101, 'loss': 9734.5498}\n",
      "{'t': 201, 'loss': 7118.5664}\n",
      "{'t': 301, 'loss': 6898.1997}\n",
      "{'t': 401, 'loss': 6120.0596}\n",
      "{'t': 501, 'loss': 6192.7383}\n",
      "{'t': 601, 'loss': 6096.2578}\n",
      "{'t': 701, 'loss': 5999.6538}\n",
      "{'t': 801, 'loss': 5747.8633}\n",
      "{'t': 901, 'loss': 5227.0811}\n",
      "{'t': 1001, 'loss': 6023.1987}\n",
      "{'t': 1101, 'loss': 5398.0654}\n",
      "{'t': 1201, 'loss': 5188.6304}\n",
      "{'t': 1301, 'loss': 5179.0459}\n",
      "{'t': 1401, 'loss': 4920.7388}\n",
      "{'t': 1501, 'loss': 5314.5898}\n",
      "{'t': 1601, 'loss': 5199.1455}\n",
      "{'t': 1701, 'loss': 4849.3906}\n",
      "{'t': 1801, 'loss': 5242.9043}\n",
      "{'t': 1901, 'loss': 4936.3003}\n",
      "{'t': 2001, 'loss': 4767.4097}\n",
      "{'t': 2101, 'loss': 5226.5532}\n",
      "{'t': 2201, 'loss': 5237.6997}\n",
      "{'t': 2301, 'loss': 4867.6362}\n",
      "{'t': 2401, 'loss': 4701.623}\n",
      "{'t': 2501, 'loss': 4900.938}\n",
      "{'t': 2601, 'loss': 4885.106}\n",
      "{'t': 2701, 'loss': 5189.3833}\n",
      "{'t': 2801, 'loss': 4792.2871}\n",
      "{'t': 2901, 'loss': 4619.9199}\n"
     ]
    }
   ],
   "source": [
    "# DATA\n",
    "sess = ed.get_session()\n",
    "# N is number of samples (ori x trials) and D is number of neurons\n",
    "N, D = Xtrain_scaled.shape[0], Xtrain_scaled.shape[1]\n",
    "\n",
    "########## DESIGN COVARIANCE MATRIX ##########\n",
    "w_covs = []\n",
    "#tau = tf.nn.softplus(tf.Variable(tf.random_normal([D])))\n",
    "tau = tf.nn.softplus(tf.Variable(tf.random_normal([D])))\n",
    "\n",
    "#sparsity = tf.nn.softplus(tf.Variable(tf.random_normal([D])))\n",
    "sparsity = tf.nn.softplus(tf.Variable(tf.random_normal([])))\n",
    "\n",
    "\n",
    "# for each neuron\n",
    "for d in range(D):\n",
    "    # Design precision matrix\n",
    "    A = np.zeros((C-1,C))\n",
    "    # for each orientation\n",
    "    for i in range(C-1):\n",
    "        A[i,i] = -1\n",
    "        A[i,i+1] = 1\n",
    "    precision = A.T.dot(A) #+ .1 * np.identity(C) # precision = A^T.dot(A)\n",
    "    precision = tau[d] * precision + sparsity * np.identity(C)\n",
    "    precision = precision + .1 * np.identity(C) # guarantees full rank\n",
    "\n",
    "    cov = tf.matrix_inverse(precision)[:-1,:-1]\n",
    "    w_covs.append(cov)\n",
    "w_cov = tf.stack(w_covs)\n",
    "\n",
    "########## MODEL ##########\n",
    "X = tf.placeholder(tf.float32, [N, D])\n",
    "w = MultivariateNormalFullCovariance(loc = tf.zeros([D,C-1]), covariance_matrix = tf.cast(w_cov, tf.float32))\n",
    "b = Normal(loc = tf.zeros(C-1), scale= tf.ones(C-1))\n",
    "logits = tf.matmul(X, w) + b\n",
    "logits = tf.concat([logits, np.zeros((N, 1))], axis = 1)\n",
    "y = Categorical(logits = logits)\n",
    "\n",
    "########## INFERENCE ##########\n",
    "qw_loc = tf.Variable(tf.random_normal([D, C-1]))\n",
    "qw_scale = tf.nn.softplus(tf.Variable(tf.random_normal([D,C-1])))\n",
    "\n",
    "qb_loc = tf.Variable(tf.random_normal([C-1]))\n",
    "qb_scale = tf.nn.softplus(tf.Variable(tf.random_normal([])))\n",
    "\n",
    "qw = Normal(loc = qw_loc, scale = qw_scale)\n",
    "qb = Normal(loc = qb_loc, scale = qb_scale)\n",
    "\n",
    "inference = ed.KLqp({w: qw, b: qb}, data={X: Xtrain_scaled, y: Ytrain})\n",
    "inference.initialize(n_iter = 3000)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "init.run()\n",
    "learning_curve = []\n",
    "for _ in range(inference.n_iter):\n",
    "    info_dict = inference.update()\n",
    "    if _%100 == 0:\n",
    "        print(info_dict)\n",
    "    learning_curve.append(info_dict['loss'])\n",
    "inference.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99778473309\n",
      "[ 0.90833333  0.99259259  1.          1.          1.          1.        ]\n"
     ]
    }
   ],
   "source": [
    "########## EVAL ##########\n",
    "qw_mod = tf.concat([qw.mean(), np.zeros((qw.shape[0],1))], axis=1)\n",
    "qb_mod = tf.concat([qb.mean(), np.zeros((1))], axis=0)\n",
    "logits = tf.matmul(tf.cast(Xtest_scaled, tf.float32), qw_mod) + qb_mod\n",
    "print(compute_average_auc(tf.nn.softmax(logits).eval(), Ytest_hot))\n",
    "print(evaluate_multiclass_model(x_test_scaled_3d, qw_mod.eval().T, qb_mod.eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1604b9128>]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAECCAYAAAASDQdFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15c68cbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(qw_mod.eval()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tridiag_tau_each_neuron = [0.89212963, 0.98472222, 0.99953704, 0.99953704, 0.99953704, 1.]\n",
    "tridiag_single_tau = [ 0.88935185  0.99027778  0.99861111  0.99953704  0.99953704  1.        ]\n",
    "tridiag_single_tau_single_spar = [ 0.90185185  0.98981481  1.          0.99953704  0.99953704  1.        ]\n",
    "\n",
    "gp = [ 0.90138889  0.99027778  1.          0.99953704  0.99953704  1.        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(qw_mod.eval()[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tau.eval()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########## EVAL ##########\n",
    "qw_mod = tf.concat([qw.mean(), np.zeros((qw.shape[0],1))], axis=1)\n",
    "qb_mod = tf.concat([qb.mean(), np.zeros((1))], axis=0)\n",
    "logits = tf.matmul(tf.cast(Xtest_scaled, tf.float32), qw_mod) + qb_mod\n",
    "print(compute_average_auc(tf.nn.softmax(logits).eval(), Ytest_hot))\n",
    "print(evaluate_multiclass_model(x_test_scaled_3d, qw_mod.eval().T, qb_mod.eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(np.arange(len(tau.eval())),tau.eval())\n",
    "plt.ylabel(\"tau\")\n",
    "plt.xlabel(\"neuron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(113),sparsity.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "tau_per_neuron_vi = [0.81481481, 0.90185185, 0.96666667, 0.98564815, 0.99444444, 0.99722222]\n",
    "l2_prior = [0.74027778, 0.81759259, 0.92407407, 0.96342593, 0.98888889, 0.99305556]\n",
    "\n",
    "xticks = [5, 10, 15, 20, 25, 30]\n",
    "plt.plot(xticks, l2_prior, label=\"l2 prior\")\n",
    "plt.plot(xticks, tau_per_neuron_vi, label=\"new model\")\n",
    "plt.ylabel(\"probability correct\")\n",
    "plt.xlabel(\"orientation difference (degrees)\")\n",
    "plt.legend(loc = 'lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rbf(tf.cast(np.reshape(np.arange((3)), (-1,1)), tf.float32)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rbf(tf.cast(np.reshape(np.arange((5)), (-1,1)), tf.float32)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.reshape(np.concatenate((np.arange(1,38), np.arange(start=36, stop=1, step=-1))), (-1,1))\n",
    "rbf(tf.cast(x, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.arange(start=36, stop=1, step=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(np.reshape(np.concatenate((np.arange(1,38), np.arange(start=36, stop=2, step=-1))), (-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.cholesky(rbf_kernel).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kern = np.reshape(np.arange(0,36), (-1,1))\n",
    "\n",
    "rbf_kernel = rbf(X = tf.cast(kern, tf.float32))\n",
    "rbf_kernel = tf.nn.softplus(rbf_kernel + .1 * tf.identity(rbf_kernel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from edward.util import rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Softplus_13:0' shape=(36, 36) dtype=float32>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rbf_cos_kernel(theta):\n",
    "    '''\n",
    "        RBF kernel applied to distances on a circle using radians\n",
    "    '''\n",
    "    variance = 1.0\n",
    "    lengthscale = 1.0\n",
    "    kernel = np.zeros((len(theta), len(theta)))\n",
    "    for i in range(len(theta)):\n",
    "        for j in range(len(theta)):\n",
    "            radians = ((theta[j] - theta[i]) / len(theta)) * 2 * np.pi\n",
    "            kernel[i,j] = variance * (np.cos(radians) / lengthscale) ** 2\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.       ,  0.0954915,  0.6545085,  0.6545085,  0.0954915],\n",
       "       [ 0.0954915,  1.       ,  0.0954915,  0.6545085,  0.6545085],\n",
       "       [ 0.6545085,  0.0954915,  1.       ,  0.0954915,  0.6545085],\n",
       "       [ 0.6545085,  0.6545085,  0.0954915,  1.       ,  0.0954915],\n",
       "       [ 0.0954915,  0.6545085,  0.6545085,  0.0954915,  1.       ]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = np.reshape(np.arange(0,5), (-1,1))\n",
    "\n",
    "rbf_cos_kernel(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08726646])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((theta[2] - theta[1]) / 72) * 2 * np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix normal prior, specifying cov matrix for neuron x neurion and ori x ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA\n",
    "sess = ed.get_session()\n",
    "# N is number of samples (ori x trials) and D is number of neurons\n",
    "N, D = Xtrain_scaled.shape[0], Xtrain_scaled.shape[1]\n",
    "\n",
    "########## DESIGN COVARIANCE MATRIX ##########\n",
    "w_covs = []\n",
    "#tau = tf.nn.softplus(tf.Variable(tf.random_normal([D])))\n",
    "tau = tf.nn.softplus(tf.Variable(tf.random_normal([D])))\n",
    "\n",
    "#sparsity = tf.nn.softplus(tf.Variable(tf.random_normal([D])))\n",
    "sparsity = tf.nn.softplus(tf.Variable(tf.random_normal([])))\n",
    "\n",
    "\n",
    "# for each neuron\n",
    "for d in range(D):\n",
    "    # Design precision matrix\n",
    "    A = np.zeros((C-1,C))\n",
    "    # for each orientation\n",
    "    for i in range(C-1):\n",
    "        A[i,i] = -1\n",
    "        A[i,i+1] = 1\n",
    "    precision = A.T.dot(A) #+ .1 * np.identity(C) # precision = A^T.dot(A)\n",
    "    precision = tau[d] * precision + sparsity * np.identity(C)\n",
    "    precision = precision + .1 * np.identity(C) # guarantees full rank\n",
    "\n",
    "    cov = tf.matrix_inverse(precision)[:-1,:-1]\n",
    "    w_covs.append(cov)\n",
    "w_cov = tf.stack(w_covs)\n",
    "\n",
    "########## MODEL ##########\n",
    "X = tf.placeholder(tf.float32, [N, D])\n",
    "w = MultivariateNormalFullCovariance(loc = tf.zeros([D,C-1]), covariance_matrix = tf.cast(w_cov, tf.float32))\n",
    "b = Normal(loc = tf.zeros(C-1), scale= tf.ones(C-1))\n",
    "logits = tf.matmul(X, w) + b\n",
    "logits = tf.concat([logits, np.zeros((N, 1))], axis = 1)\n",
    "y = Categorical(logits = logits)\n",
    "\n",
    "########## INFERENCE ##########\n",
    "qw_loc = tf.Variable(tf.random_normal([D, C-1]))\n",
    "qw_scale = tf.nn.softplus(tf.Variable(tf.random_normal([D,C-1])))\n",
    "\n",
    "qb_loc = tf.Variable(tf.random_normal([C-1]))\n",
    "qb_scale = tf.nn.softplus(tf.Variable(tf.random_normal([])))\n",
    "\n",
    "qw = Normal(loc = qw_loc, scale = qw_scale)\n",
    "qb = Normal(loc = qb_loc, scale = qb_scale)\n",
    "\n",
    "inference = ed.KLqp({w: qw, b: qb}, data={X: Xtrain_scaled, y: Ytrain})\n",
    "inference.initialize(n_iter = 3000)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "init.run()\n",
    "learning_curve = []\n",
    "for _ in range(inference.n_iter):\n",
    "    info_dict = inference.update()\n",
    "    if _%100 == 0:\n",
    "        print(info_dict)\n",
    "    learning_curve.append(info_dict['loss'])\n",
    "inference.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## A gaussian process prior on the weights..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t': 1, 'loss': 74036.875}\n",
      "{'t': 101, 'loss': 10442.131}\n",
      "{'t': 201, 'loss': 8070.2295}\n",
      "{'t': 301, 'loss': 6972.7627}\n",
      "{'t': 401, 'loss': 6992.1924}\n",
      "{'t': 501, 'loss': 7005.603}\n",
      "{'t': 601, 'loss': 6402.437}\n",
      "{'t': 701, 'loss': 6215.104}\n",
      "{'t': 801, 'loss': 6310.7803}\n",
      "{'t': 901, 'loss': 5896.0811}\n",
      "{'t': 1001, 'loss': 6200.0225}\n",
      "{'t': 1101, 'loss': 5669.3164}\n",
      "{'t': 1201, 'loss': 5850.2812}\n",
      "{'t': 1301, 'loss': 5373.6909}\n",
      "{'t': 1401, 'loss': 5697.3008}\n",
      "{'t': 1501, 'loss': 5688.6807}\n",
      "{'t': 1601, 'loss': 5534.938}\n",
      "{'t': 1701, 'loss': 5661.8545}\n",
      "{'t': 1801, 'loss': 5322.7744}\n",
      "{'t': 1901, 'loss': 5397.3345}\n",
      "{'t': 2001, 'loss': 5302.4473}\n",
      "{'t': 2101, 'loss': 5523.418}\n",
      "{'t': 2201, 'loss': 5577.0259}\n",
      "{'t': 2301, 'loss': 5398.1602}\n",
      "{'t': 2401, 'loss': 5144.5708}\n",
      "{'t': 2501, 'loss': 5187.0542}\n",
      "{'t': 2601, 'loss': 5499.3066}\n",
      "{'t': 2701, 'loss': 5586.3721}\n",
      "{'t': 2801, 'loss': 5265.834}\n",
      "{'t': 2901, 'loss': 5135.2197}\n",
      "0.997799513128\n",
      "[ 0.91296296  0.99259259  0.99907407  1.          1.          1.        ]\n"
     ]
    }
   ],
   "source": [
    "from edward.util import rbf\n",
    "\n",
    "\n",
    "# DATA\n",
    "sess = ed.get_session()\n",
    "# N is number of samples (ori x trials) and D is number of neurons\n",
    "N, D = Xtrain_scaled.shape[0], Xtrain_scaled.shape[1]\n",
    "\n",
    "########## MODEL ##########\n",
    "X = tf.placeholder(tf.float32, [N, D])\n",
    "cov = tf.nn.softplus(tf.random_normal([C-1,C-1]))\n",
    "\n",
    "####### the X matrix should NOT be cov, but rather 1....72\n",
    "length = tf.nn.softplus(tf.Variable(tf.random_normal([])))\n",
    "var = tf.nn.softplus(tf.Variable(tf.random_normal([])))\n",
    "\n",
    "kern = tf.cast(np.reshape(np.concatenate((np.arange(1,38), np.arange(start=36, stop=1, step=-1))), (-1,1)), tf.float32)\n",
    "#kern = np.reshape(np.arange(0,36), (-1,1))\n",
    "\n",
    "rbf_kernel = rbf(X = kern, lengthscale = length, variance = var)[:-1,:-1]\n",
    "#rbf_kernel = rbf_kernel[:-1,:-1]\n",
    "#rbf_kernel = (rbf_kernel + .1 * tf.identity(rbf_kernel))[:-1,:-1]\n",
    "                 #lengthscale = lengthscale_param, variance = variance_param)z\n",
    "w = MultivariateNormalTriL(loc = tf.zeros([D,C-1]), \n",
    "                           scale_tril = rbf_kernel)\n",
    "\n",
    "\n",
    "#lengthscale_param = tf.nn.softplus(tf.Variable(tf.random_normal([])))\n",
    "#variance_param = tf.nn.softplus(tf.Variable(tf.random_normal([])))\n",
    "\n",
    "#w = MultivariateNormalTriL(loc = tf.zeros([D,C-1]), \n",
    "#                           scale_tril = tf.cholesky(rbf(X = cov, lengthscale = lengthscale_param, variance = variance_param)))\n",
    "\n",
    "b = Normal(loc = tf.zeros(C-1), scale= tf.ones(C-1))\n",
    "logits = tf.matmul(X, w) + b\n",
    "logits = tf.concat([logits, np.zeros((N, 1))], axis = 1)\n",
    "y = Categorical(logits = logits)\n",
    "\n",
    "########## INFERENCE ##########\n",
    "qw_loc = tf.Variable(tf.random_normal([D, C-1]))\n",
    "qw_scale = tf.nn.softplus(tf.Variable(tf.random_normal([D,C-1])))\n",
    "\n",
    "qb_loc = tf.Variable(tf.random_normal([C-1]))\n",
    "qb_scale = tf.nn.softplus(tf.Variable(tf.random_normal([])))\n",
    "\n",
    "qw = Normal(loc = qw_loc, scale = qw_scale)\n",
    "qb = Normal(loc = qb_loc, scale = qb_scale)\n",
    "\n",
    "inference = ed.KLqp({w: qw, b: qb}, \n",
    "                    data={X: Xtrain_scaled, y: Ytrain})\n",
    "inference.initialize(n_iter = 3000)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "init.run()\n",
    "learning_curve = []\n",
    "for _ in range(inference.n_iter):\n",
    "    info_dict = inference.update()\n",
    "    if _%100 == 0:\n",
    "        print(info_dict)\n",
    "    learning_curve.append(info_dict['loss'])\n",
    "inference.finalize()\n",
    "\n",
    "\n",
    "########## EVAL ##########\n",
    "qw_mod = tf.concat([qw.mean(), np.zeros((qw.shape[0],1))], axis=1)\n",
    "qb_mod = tf.concat([qb.mean(), np.zeros((1))], axis=0)\n",
    "logits = tf.matmul(tf.cast(Xtest_scaled, tf.float32), qw_mod) + qb_mod\n",
    "print(compute_average_auc(tf.nn.softmax(logits).eval(), Ytest_hot))\n",
    "print(evaluate_multiclass_model(x_test_scaled_3d, qw_mod.eval().T, qb_mod.eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997799513128\n",
      "[ 0.91296296  0.99259259  0.99907407  1.          1.          1.        ]\n"
     ]
    }
   ],
   "source": [
    "########## EVAL ##########\n",
    "qw_mod = tf.concat([qw.mean(), np.zeros((qw.shape[0],1))], axis=1)\n",
    "qb_mod = tf.concat([qb.mean(), np.zeros((1))], axis=0)\n",
    "logits = tf.matmul(tf.cast(Xtest_scaled, tf.float32), qw_mod) + qb_mod\n",
    "print(compute_average_auc(tf.nn.softmax(logits).eval(), Ytest_hot))\n",
    "print(evaluate_multiclass_model(x_test_scaled_3d, qw_mod.eval().T, qb_mod.eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(w.eval()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.4581113, 0.50333989)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length.eval(), var.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(w.eval()[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.4581113, 0.50333989)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length.eval(), var.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17a246748>]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAECCAYAAAASDQdFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x178c087b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(qw_mod[0].eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x173486cc0>]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAECCAYAAAAB2kexAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEMEBXWCIIghgoI6QRDEEPH/AwXPD+tvN9HBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x163bf79b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(qw_mod[0].eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### MODEL working VI for multi-class setting and converges quickly\n",
    "C = 72\n",
    "N = Xtrain_scaled.shape[0]\n",
    "X = tf.placeholder(tf.float32, [N, D])\n",
    "#w = MultivariateNormalTriL(loc = tf.zeros((D,C-1)), scale_tril = tf.cast(sample_cov[:-1,:-1], tf.float32))\n",
    "w = MultivariateNormalTriL(loc = tf.zeros((D,C-1)), \n",
    "                           scale_tril = rbf(tf.cast(np.mean(x_train_scaled, axis=1), tf.float32))[:-1,:-1])\n",
    "\n",
    "b = Normal(loc = tf.zeros(C-1), scale = 1 * tf.ones([]))\n",
    "\n",
    "logits = tf.matmul(X, w) + b\n",
    "logits = tf.concat([logits, np.zeros((N, 1))], axis = 1)\n",
    "\n",
    "y = Multinomial(logits = tf.nn.softmax(logits), total_count=1.0)\n",
    "\n",
    "# INFERENCE\n",
    "qw_loc = tf.Variable(tf.random_normal([D,C-1]))\n",
    "qw_scale = tf.nn.softplus(tf.Variable(tf.random_normal([C-1])))\n",
    "\n",
    "qb_loc = tf.Variable(tf.random_normal([C-1]))\n",
    "qb_scale = tf.nn.softplus(tf.Variable(tf.random_normal([])))\n",
    "\n",
    "qw = Normal(loc = qw_loc, scale = qw_scale)\n",
    "qb = Normal(loc = qb_loc, scale = qb_scale)\n",
    "\n",
    "inference = ed.KLqp({w: qw, b: qb}, data={X: Xtrain_scaled, y: Ytrain_hot})\n",
    "inference.initialize(n_iter = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = ed.get_session()\n",
    "init = tf.global_variables_initializer()\n",
    "init.run()\n",
    "learning_curve = []\n",
    "for _ in range(inference.n_iter):\n",
    "    info_dict = inference.update()\n",
    "    if _%1000 == 0:\n",
    "        print(info_dict)\n",
    "    learning_curve.append(info_dict['loss'])\n",
    "inference.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.zeros((C-1,C))\n",
    "for i in range(C-1):\n",
    "    A[i,i] = -1\n",
    "    A[i,i+1] = 1\n",
    "precision = A.T.dot(A) + .01 * np.identity(C) # A^T.dot(A) + .1 * I for invertability\n",
    "lambda_1 = 1\n",
    "precision = lambda_1 * precision\n",
    "#precision = precision + 1 * np.identity(C) # add sparsity prior \n",
    "cov_matrix = tf.matrix_inverse(precision)\n",
    "cov_matrix_chol = tf.cholesky(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.zeros((D-1,D))\n",
    "for i in range(D-1):\n",
    "    A[i,i] = -1\n",
    "    A[i,i+1] = 1\n",
    "precision = A.T.dot(A) + .01 * np.identity(D) # A^T.dot(A) + .1 * I for invertability\n",
    "lambda_1 = 1\n",
    "precision = lambda_1 * precision\n",
    "precision = precision + 1 * np.identity(D) # add sparsity prior \n",
    "cov_matrix = tf.matrix_inverse(precision)\n",
    "cov_matrix_chol = tf.cholesky(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lambdas = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6]    \n",
    "\n",
    "C = 72\n",
    "N = Xtrain_scaled.shape[0]\n",
    "X = tf.placeholder(tf.float32, [N, D])\n",
    "#w = Normal(loc = tf.zeros((D,C-1)), scale = 1 * tf.ones((D,C-1)))\n",
    "w = MultivariateNormalTriL(loc = tf.zeros((D,C-1)), \n",
    "                           scale_tril = tf.cast(tf.cholesky(cov_matrix[:-1,:-1]), tf.float32))\n",
    "\n",
    "# define a (batch of D) C-1 multivariate normals\n",
    "#w = MultivariateNormalFullCovariance(loc = tf.zeros((D,C-1)),\n",
    "#                                     covariance_matrix = tf.cast(cov_matrix[:-1,:-1], tf.float32))\n",
    "\n",
    "#w = MultivariateNormalTriL(loc = tf.zeros((D,C-1)),\n",
    "#                                     scale_tril = tf.cast(cov_matrix_chol[:-1,:-1], tf.float32))\n",
    "\n",
    "#w = MultivariateNormalTriL(loc = tf.zeros((D,C-1)), scale_tril = rbf_kernel)\n",
    "#w = Normal(loc = tf.zeros((D,C-1)), scale = 1* tf.ones(C-1))\n",
    "#b = Normal(loc = tf.zeros(C-1, 1), scale = 1 * tf.ones([]))\n",
    "\n",
    "logits = tf.matmul(X, (w)) #+ b\n",
    "logits = tf.concat([logits, np.zeros((N, 1))], axis = 1)\n",
    "\n",
    "y = Categorical(probs = tf.nn.softmax(logits))\n",
    "\n",
    "\n",
    "# INFERENCE\n",
    "qw_loc = tf.Variable(tf.random_normal([D,C-1]))\n",
    "#qb_loc = tf.Variable(tf.zeros([C-1]))\n",
    "\n",
    "qw = PointMass(params = qw_loc)\n",
    "#qb = PointMass(params = qb_loc)\n",
    "\n",
    "inference = ed.MAP({w: qw}, data={X: Xtrain_scaled, y: Ytrain})\n",
    "inference.initialize(n_iter = 5000)\n",
    "\n",
    "sess = ed.get_session()\n",
    "init = tf.global_variables_initializer()\n",
    "init.run()\n",
    "learning_curve = []\n",
    "for _ in range(inference.n_iter):\n",
    "    info_dict = inference.update()\n",
    "    if _%1000 == 0:\n",
    "        print(info_dict)\n",
    "    learning_curve.append(info_dict['loss'])\n",
    "inference.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "qw_loc = tf.Variable(tf.random_normal([D,C-1]))\n",
    "qw_scale = tf.nn.softplus(tf.Variable(tf.random_normal([D,C-1])))\n",
    "\n",
    "qb_loc = tf.Variable(tf.random_normal([C-1]))\n",
    "qb_scale = tf.nn.softplus(tf.Variable(tf.random_normal([])))\n",
    "\n",
    "qw = Normal(loc = qw_loc, scale = qw_scale)\n",
    "qb = Normal(loc = qb_loc, scale = qb_scale)\n",
    "\n",
    "inference = ed.KLqp({w: qw, b: qb}, data={X: Xtrain_scaled, y: Ytrain})\n",
    "inference.initialize(n_iter = 10000)\n",
    "'''\n",
    "'''\n",
    "# EVALUATION ON TEST DATA\n",
    "qw_mod = tf.concat([tf.transpose(qw.mean()), np.zeros((58,1))], axis=1)\n",
    "qb_mod = tf.concat([qb.mean(), np.zeros((1))], axis=0)\n",
    "logits = tf.matmul(tf.cast(sklearn.preprocessing.scale(Xtest), tf.float32), qw_mod) + qb_mod\n",
    "print(compute_average_auc(tf.nn.softmax(logits).eval(), Ytest_hot))\n",
    "\n",
    "print(evaluate_multiclass_model(x_test_scaled, qw_mod.eval(), qb_mod.eval()))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pystan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ytrain=Ytrain+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### MAP estimation with beta ~ normal(0,1)\n",
    "\n",
    "# K outcomes\n",
    "multi_logit_code = \"\"\"\n",
    "data {\n",
    "    int<lower=2> K; // num orientations\n",
    "    int<lower=0> N; // num samples\n",
    "    int<lower=1> D; // num features\n",
    "    int y[N];\n",
    "    vector[D] x[N];\n",
    "}\n",
    "parameters {\n",
    "    matrix[K,D] beta;\n",
    "    vector[K] intercept;\n",
    "}\n",
    "model {\n",
    "    for (k in 1:K) {\n",
    "        beta[k] ~ normal(0,1);\n",
    "    }\n",
    "    //for (d in 1:D) {\n",
    "    //    beta[:,d] ~ normal(0,1);\n",
    "    //}\n",
    "    intercept ~ normal(0,1);\n",
    "    for (n in 1:N) {\n",
    "       y[n] ~ categorical_logit(beta * x[n] + intercept);\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "dat = {'K': 72, 'N': 2520, 'D': 58, 'x': Xtrain_scaled, 'y': Ytrain}\n",
    "\n",
    "sm = pystan.StanModel(model_code = multi_logit_code)\n",
    "fit = sm.optimizing(data= dat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta_ori = fit['beta']\n",
    "intercept_ori = fit['intercept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_multiclass_model(x_test_scaled_3d, beta_ori, intercept_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### MAP estimation with beta ~ normal(0,1)\n",
    "\n",
    "# K outcomes\n",
    "multi_logit_code = \"\"\"\n",
    "data {\n",
    "    int<lower=2> K; // num orientations\n",
    "    int<lower=0> N; // num samples\n",
    "    int<lower=1> D; // num neurons\n",
    "    int y[N];\n",
    "    vector[D] x[N];\n",
    "}\n",
    "transformed data {\n",
    "    row_vector[D] zeros;\n",
    "    zeros = rep_row_vector(0, D);\n",
    "}\n",
    "parameters {\n",
    "    matrix[K-1, D] beta_raw;\n",
    "    vector[K] intercept;\n",
    "    real<lower=0> sigma[K];\n",
    "    real<lower=0> sigma_intercept;\n",
    "}\n",
    "transformed parameters {\n",
    "    matrix[K, D] beta;\n",
    "    beta = append_row(beta_raw, zeros);\n",
    "}\n",
    "model {\n",
    "    for (k in 1:K) {\n",
    "        beta[k] ~ normal(0,sigma[k]);\n",
    "    }\n",
    "    //for (d in 1:D) {\n",
    "    //    beta[:,d] ~ normal(0,1);\n",
    "    //}\n",
    "    intercept ~ normal(0,sigma_intercept);\n",
    "    for (n in 1:N) {\n",
    "       y[n] ~ categorical_logit(beta * x[n] + intercept);\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "dat = {'K': 72, 'N': 2520, 'D': 58, 'x': Xtrain, 'y': Ytrain}\n",
    "\n",
    "sm = pystan.StanModel(model_code = multi_logit_code)\n",
    "fit = sm.vb(data= dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gaussian process prior\n",
    "multi_logit_code = \"\"\"\n",
    "data {\n",
    "    int<lower=2> K;\n",
    "    int<lower=0> N;\n",
    "    int<lower=1> D;\n",
    "    int y[N];\n",
    "    vector[D] x[N];\n",
    "}\n",
    "transformed data {\n",
    "    //cov_matrix[K] Kern;\n",
    "    //K = cov_exp_quad()\n",
    "    \n",
    "}\n",
    "parameters {\n",
    "    matrix[K,D] beta;\n",
    "    vector[K] intercept;\n",
    "    //cov_matrix[K] Kern;\n",
    "    //K = cov_exp_quad(beta, 1 1);\n",
    "}\n",
    "model {\n",
    "    for (d in 1:D) {\n",
    "        beta[:,d] ~ multi_normal(0, Kern);\n",
    "    }\n",
    "    // beta[:,d] ~ GP[0, squared rbf kernel] model each column as a gp \n",
    "    intercept ~ normal(0,1);\n",
    "    for (n in 1:N) {\n",
    "       y[n] ~ categorical_logit(beta * x[n] + intercept);\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "dat = {'K': 4, 'N': 140, 'D': 58, 'x': Xtrain_n, 'y': yt}\n",
    "\n",
    "sm = pystan.StanModel(model_code = multi_logit_code)\n",
    "fit = sm.vb(data= dat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
